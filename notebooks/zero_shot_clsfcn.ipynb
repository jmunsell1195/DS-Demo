{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install transformers --quiet\n",
    "# !pip3 install datasets --quiet\n",
    "# !pip3 install torch --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this block of code to input the text and the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer,AutoConfig\n",
    "\n",
    "# Start with checkpoint \"bart-large-mnli\"\n",
    "checkpoint = 'facebook/bart-large-mnli'\n",
    "checkpoint2 = \"joeddav/xlm-roberta-large-xnli\"\n",
    "\n",
    "# Load the model and tokenizer with pre-trained weights from the checkpoint\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "# Grab a snapshot of the model configuration for later parameter tuning\n",
    "config = AutoConfig.from_pretrained(checkpoint)\n",
    "\n",
    "# User enters the text they want classified as well as any number of possible labels\n",
    "# premise = input(\"Please enter some text to be classified\")\n",
    "# num_labels = input('Enter the number of labels')\n",
    "# labels = [input(f\"Please enter the number{i+1} label\") for i in range(int(num_labels))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this block of code to perform the prediction and \"return\" the most probable class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmunse/anaconda3/envs/test/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2335: FutureWarning: The `truncation_strategy` argument is deprecated and will be removed in a future version, use `truncation=True` to truncate examples to a max length. You can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to truncate to the maximal input size of the model (e.g. 512 for Bert).  If you have pairs of inputs, you can give a specific truncation strategy selected among `truncation='only_first'` (will only truncate the first sentence in the pairs) `truncation='only_second'` (will only truncate the second sentence in the pairs) or `truncation='longest_first'` (will iteratively remove tokens from the longest sentence in the pairs).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This team is a lot of fun, we have been very productive and learning a lot of new things\n",
      "\n",
      "work\n",
      "\n",
      "{'cars': 0.21023792028427124, 'work': 0.7903614640235901, 'apples': 0.13244618475437164}\n"
     ]
    }
   ],
   "source": [
    "# Define empty dict that will be used for the output\n",
    "output = {}\n",
    "\n",
    "# For each label\n",
    "for label in labels:\n",
    "    # Autotokenizer encodes text input with current label\n",
    "    tok = tokenizer.encode(premise, label, return_tensors='pt',truncation_strategy='only_first')  \n",
    "    \n",
    "    # classify tokenized data \n",
    "    logits = nli_model(tok)[0]\n",
    "\n",
    "    # retrieve the probability that the current label is correct\n",
    "    entail_contradiction_logits = logits[:,[0,2]]\n",
    "    probs1 = entail_contradiction_logits.softmax(dim=1)\n",
    "    output[label] = float(probs1[:,1])\n",
    "\n",
    "# Select the hist probability (value)\n",
    "max_val = max(output.values())\n",
    "\n",
    "# Print the premise and the key (label) corresponding to the highest probability\n",
    "print(premise)\n",
    "print('')\n",
    "# Print the label corresponding to the highest probability\n",
    "print(next(k for k,v in output.items() if v == max_val))\n",
    "print('')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.modeling_outputs.Seq2SeqSequenceClassifierOutput"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nli_model(tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartConfig {\n",
       "  \"_name_or_path\": \"facebook/bart-large-mnli\",\n",
       "  \"_num_labels\": 3,\n",
       "  \"activation_dropout\": 0.0,\n",
       "  \"activation_function\": \"gelu\",\n",
       "  \"add_final_layer_norm\": false,\n",
       "  \"architectures\": [\n",
       "    \"BartForSequenceClassification\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classif_dropout\": 0.0,\n",
       "  \"classifier_dropout\": 0.0,\n",
       "  \"d_model\": 1024,\n",
       "  \"decoder_attention_heads\": 16,\n",
       "  \"decoder_ffn_dim\": 4096,\n",
       "  \"decoder_layerdrop\": 0.0,\n",
       "  \"decoder_layers\": 12,\n",
       "  \"decoder_start_token_id\": 2,\n",
       "  \"dropout\": 0.1,\n",
       "  \"encoder_attention_heads\": 16,\n",
       "  \"encoder_ffn_dim\": 4096,\n",
       "  \"encoder_layerdrop\": 0.0,\n",
       "  \"encoder_layers\": 12,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"forced_eos_token_id\": 2,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"contradiction\",\n",
       "    \"1\": \"neutral\",\n",
       "    \"2\": \"entailment\"\n",
       "  },\n",
       "  \"init_std\": 0.02,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"label2id\": {\n",
       "    \"contradiction\": 0,\n",
       "    \"entailment\": 2,\n",
       "    \"neutral\": 1\n",
       "  },\n",
       "  \"max_position_embeddings\": 1024,\n",
       "  \"model_type\": \"bart\",\n",
       "  \"normalize_before\": false,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"output_past\": false,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"scale_embedding\": false,\n",
       "  \"transformers_version\": \"4.22.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "beeac2e85e13a42cd30369aae72be3991bad01c857e8f39f76b9988b0534510b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
